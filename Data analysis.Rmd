---
title: "Descriptive data analysis"
author: "Luke Qian"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, tidy.opts = list(width.cutoff = 60), tidy = TRUE)
```

## 1. Load packages
```{r, warning=FALSE, message=FALSE}
library(tidyverse)
library(ggplot2)
library(readxl)
library(skimr)
```


## 2. Data preparation


### 2.1 Survey data
```{r, message=FALSE}
# load the datasets
farmSurvey = read_csv("Data/Farm Survey data.csv")
microTest = read_csv("Data/Raw Milk Micro Data.csv") 

# merge the two datasets
surveyMicroData = full_join(farmSurvey, microTest, by = c("FarmID", "Sampling"))

# simplify column names
colnames(surveyMicroData) = c("FarmID", "Sampling", "Loc", "University", "CertYear", "HouseStyle", 
               "PastureTime", "StallNumPerArea", "CowNumPerArea", "StockDen", "Bed", 
               "BedAdd","BedAddFreq", "StallCleanFreq", "CowNum", "MilkFreq", "PplNumPerWk",
               "PplNumPerShift", "NonFamEmp", "NonFamEmpNum", "FullEmp", "FullEmpNum",
               "PartEmp", "PartEmpNum", "Glove", "GloveFreq", "PreDip", "PreDipType",
               "PostDip", "PostDipType", "UdderSti", "ClipFlame", "CowMilkLoc", "Parlor",
               "ParlorClean", "CowParlorClean", "CowWaitMilk", "HoldClean", "CowHoldClean",
               "TeatEndScore", "TeatPercent3to4", "UdderHygScore", "UdderPercent3to4",
               "TowelType", "TowelCleanProto", "CowTowelWipe", "CornSilage", "Haylage",
               "CornMeal", "DryHay", "Baleage", "GrassSillage", "Earlage", "Snaplage",
               "OtherFeed", "BioFeedAdd", "DryMatPercent", "FeedPurchase", "Coop",
               "ClosedHerd", "Test", "Conc", "Notes")

# skim data structure
#skim(surveyMicroData)

# modify specific surveyMicroDataa entries
surveyMicroData = surveyMicroData %>%
  ## remove lab errors
  mutate(Notes = replace_na(Notes, "No notes")) %>% 
  mutate(Notes = tolower(Notes)) %>% 
  filter(Notes != "lab error") %>% 
  ## remove no test
  filter(!is.na(Test)) %>% 
  ## stocking density
  mutate(StockDen = ifelse(StockDen == "BEDDED PACK" | 
                             StockDen == "PASTURE" |
                             StockDen == "DRY LOT", 0, StockDen),
         StockDen = round(as.numeric(sub("%", "", StockDen))/100 ,2)) %>% 
  ## cow number
  mutate(CowNum = ifelse(CowNum == "??", NA, as.numeric(CowNum)),
         CowNum = replace_na(CowNum, mean(CowNum, na.rm = TRUE))) %>% 
  ## full employee number
  mutate(FullEmpNum = ifelse(FullEmpNum == "3 family tend to robots", 0, FullEmpNum)) %>% 
  ## Cows wiped with individual towels
  mutate(CowTowelWipe = ifelse(CowTowelWipe == "robotic milker", 0, CowTowelWipe)) %>% 
  ## Percentage of dry matter
  mutate(DryMatPercent = case_when(
    DryMatPercent %in% c("31-40%", "0-10%", "21-30%", "11-20%") ~ "< 40%", 
    DryMatPercent %in% c("41-50%", "51-60%", "61-70%", "> 40%") ~ "40-70%",
    DryMatPercent %in% c(">70%", "> 70%") ~ "> 70%")) %>% 
  ## Test
  mutate(Test = ifelse(Test == "BAB`", "BAB", Test)) %>% 
  ## The frequency of adding Bed
  mutate(BedAddFreq = case_when(
    BedAddFreq %in% c("<1x/day", "2x/week", "< 1x per day") ~ "< 1x per day",
    BedAddFreq %in% c("4x per day", "2x per day") ~ ">= 2x per day",
    BedAddFreq == "1x per day" ~ "1x per day")) %>% 
  ## Bed additives
  mutate(BedAdd = if_else(BedAdd %in% c("ashes", "bacteria, limestone", "gypsum", "oyster shells"),
                          "Other", BedAdd)) %>% 
  ## Bed materials
  mutate(Bed = if_else(Bed %in% c("Other inorganic", "Recycled sand", "Sand"),
                           "OtherInorg", Bed),
         Bed = if_else(Bed %in% c("Sawdust", "Shavings"), 
                           "Sawdust", Bed)) %>% 
  ## Bio feed additives
  mutate(BioFeedAdd = if_else(BioFeedAdd == "None", "None", "Other")) %>% 
  ## Cow milk location
  mutate(CowMilkLoc = case_when(
    grepl("parlor", CowMilkLoc) ~ "Parlor",
    CowMilkLoc %in% c("Stanchions/tie stalls", "Walk through/flat barn") ~ "Stall/barn",
    CowMilkLoc == "Robots" ~ "Robot")) %>% 
  ## How many cows each towel wipes
  mutate(CowTowelWipe = ifelse(CowTowelWipe <= 1, "0-1", "> 1")) %>%
  ## Housing style
  mutate(HouseStyle = if_else(
    HouseStyle %in% c("Dry lot", "Free stalls, Bedded pack", "Free stalls, Dry lot", "Pasture"),
    "Other", HouseStyle)) %>% 
  ## Post dip type
  mutate(PostDipType = if_else(PostDipType == "Alcide based", "Other", PostDipType),
         PostDipType = if_else(is.na(PostDipType), "No PostDip", PostDipType)) %>% 
  ## Stall cleaning frequency
  mutate(StallCleanFreq = if_else(
    StallCleanFreq %in% c("< 1x/week", "1-3x/week", "1x per week", "3 or more times per week"),
    "< 1x/day", StallCleanFreq)) %>% 
  ## Udder stimulation
  mutate(UdderSti = if_else(
    UdderSti %in% c("Teats rubbed while cleaning", "Udder and teat massage", "Udder massage"),
    "Other", UdderSti)) %>% 
  ## change the towel type always to robot brush if the milk location is robot
  mutate(TowelType = if_else(CowMilkLoc == "Robot", "Robot brush", TowelType)) %>% 
  ## shorten the name for glove change frequency
  mutate(GloveFreq = case_when(
    GloveFreq == "each milking shift" ~ "1",
    GloveFreq == "3 or more times during the milking shift" ~ ">3",
    GloveFreq == "1-2x during the milking shift" ~ "1-2",
    GloveFreq == "unknown" ~ "unknown")) %>% 
  ## spread holding area cleaning practices into multiple variables
  mutate(HoldHose = grepl("Hose", HoldClean),
         HoldManScrap = grepl("Manual scraping", HoldClean),
         HoldFluSys = grepl("Flush system", HoldClean),
         HoldScrBru = grepl("Scrub brush", HoldClean)) %>% 
  select(-HoldClean) %>% 
  ## spread parlor cleaning practices into multiple variables
  mutate(ParlorHose = grepl("Hose", ParlorClean),
         ParlorManScrap = grepl("Manual scraping", ParlorClean),
         ParlorFluSys = grepl("system", ParlorClean),
         ParlorDeter = grepl("Detergent", ParlorClean),
         ParlorScrBru = grepl("Scrub brush", ParlorClean),
         ParlorRobot = grepl("Robot", ParlorClean)) %>% 
  select(-ParlorClean) %>% 
  ## spread towel cleaning protocol into two variables: bleach and drying
  mutate(TowelChloDeter = grepl("Chlorinated detergent", TowelCleanProto),
         TowelDeter = grepl("Detergent", TowelCleanProto),
         TowelBleac = grepl("Bleach", TowelCleanProto),
         TowelMacDry = grepl("Machine drying", TowelCleanProto),
         TowelLaundry = grepl("Laundry service", TowelCleanProto),
         TowelVinegar = grepl("Vinegar", TowelCleanProto),
         TowelWashMac = grepl("Washing machine", TowelCleanProto)) %>% 
  select(-TowelCleanProto) %>% 
  ## Full employee number
  mutate(FullEmpNum = replace_na(FullEmpNum, "0"),
         FullEmpNum = as.numeric(FullEmpNum)) %>% 
  select(-c(FullEmp)) %>% 
  ## Part-time employee number
  mutate(PartEmpNum = replace_na(PartEmpNum, 0),
         PartEmpNum = as.numeric(PartEmpNum)) %>% 
  ## Non family employee
  mutate(NonFamEmpNum = replace_na(NonFamEmpNum, 0),
         NonFamEmpNum = as.numeric(NonFamEmpNum)) %>% 
  ## cow holding area cleaning
  mutate(CowHoldClean = replace_na(CowHoldClean, "No holding area")) %>% 
  ## glove change frequency
  mutate(GloveFreq = replace_na(GloveFreq, "unknown")) %>% 
  ## predipping type 
  mutate(PreDipType = replace_na(PreDipType, "No predip")) %>% 
  select(-c(PreDip)) %>% 
  ## Remove useless columns (OtherFeed was removed due to high variability)
  select(-c(OtherFeed, TeatPercent3to4, UdderPercent3to4, StallNumPerArea, CowNumPerArea, Notes)) %>% 
  ## change APC to SPC
  mutate(Test = if_else(Test == "APC", "SPC", Test))

## calculate SPC variability per farm
SPCvar = surveyMicroData %>% 
  filter(Test == "SPC") %>% 
  group_by(FarmID) %>% 
  summarise(SPCvar = sd(log10(Conc), na.rm = T)) %>% 
  mutate(SPCvar = replace_na(SPCvar, mean(SPCvar, na.rm = T)))

## add SPC variability as a predictor for each farm
surveyMicroData = full_join(surveyMicroData, SPCvar, by = c("FarmID"))
surveyMicroData = surveyMicroData %>% filter(!is.na(Loc))

## Check summary stats for single variable
#surveyMicroData %>% 
#  group_by(Bed) %>% 
#  summarise(n = n()) %>% 
#  mutate(freq = n/sum(n))

## Check no duplicated rows
#surveyMicroData %>%
#  group_by(FarmID, Sampling, Test) %>%
#  filter(n() > 1L) 
```

### 2.2 Weather data 
```{r}
# load all weather data
weatherData = NULL
for (i in 1:102){
  file_name = paste("Data/Weather Data/R", i, ".xlsx", sep = "")
  excel_temp = read_excel(file_name)
  weatherData = bind_rows(weatherData, excel_temp)
}

#skim(weatherData)

# retain only relevant predictors
weatherData = weatherData %>% 
  select(farmID, datetime, tempmax, tempmin, temp, humidity, precip,
         precipcover, windgust, windspeed, solarradiation)

# data preprocessing for weather variables
weatherData = weatherData %>% 
  mutate(windgust = replace_na(windgust, 0))  
#  mutate(rain = grepl("\\brain\\b", preciptype),
#         snow = grepl("snow", preciptype),
#         ice = grepl("ice", preciptype),
#         freezingrain = grepl("freezingrain", preciptype)) %>% 
#  select(-preciptype)

#  subset data into four data frames
weather_3d = weatherData %>% dplyr::slice(seq(1, n(), by = 4))
weather_2d = weatherData %>% dplyr::slice(seq(2, n(), by = 4))
weather_1d = weatherData %>% dplyr::slice(seq(3, n(), by = 4))
weather_0d = weatherData %>% dplyr::slice(seq(4, n(), by = 4))

# create new col names
weatherVars = colnames(weatherData)
colNames_1d = paste(weatherVars, "1d", sep = "_")
colNames_2d = paste(weatherVars, "2d", sep = "_")
colNames_3d = paste(weatherVars, "3d", sep = "_")

# assign new col names to data frames
colnames(weather_3d) = colNames_3d
colnames(weather_2d) = colNames_2d
colnames(weather_1d) = colNames_1d
colnames(weather_0d) = weatherVars

# combine the dataset 
weatherData = bind_cols(weather_0d, weather_1d, weather_2d, weather_3d) %>% 
  rename(SampleTime = datetime,
         FarmID = farmID) %>% 
  mutate(FarmID = paste("R", FarmID, sep = "")) %>% 
  select(-c(farmID_1d, farmID_2d, farmID_3d,
            datetime_1d, datetime_2d, datetime_3d))


# create a dictionary that refers the sampling date from farm ID and sampling ID
Dict = read_excel("Data/SampleToDate.xlsx")
FarmID = Dict$FarmID
Dict = Dict[,-1] %>% as.data.frame()
rownames(Dict) = FarmID

# create a column in survey micro data set to include the sampling date
surveyMicroData$SampleTime = rep(NA, nrow(surveyMicroData))
for (i in 1:nrow(surveyMicroData)){
  surveyMicroData$SampleTime[i] = Dict[surveyMicroData$FarmID[i], surveyMicroData$Sampling[i]] %>% 
    format(., "%Y-%m-%d")
}
```


### 2.3 Merge data
```{r}
# combine the survey micro data set and the weather data set
FarmData = merge(surveyMicroData, weatherData, by = c("FarmID", "SampleTime"))

#write.csv(FarmData, "Data/FarmData.csv")
#skim(FarmData)
```

### 2.4 Clean the combined dataset
```{r, eval=FALSE}
FarmData = FarmData %>% 
  mutate_if(is.logical, as.numeric) %>% 
  filter(!is.na(Test) & !is.na(Conc)) 


skim(FarmData)

# prepare the dataset for modeling

FarmData %>% 
  filter(Test %in% c("MSC", "TSC", "PSC","BAB")) %>% 
  ggplot(aes(x = log10(Conc), fill = Parlor)) +
  geom_histogram(alpha = 0.5, position = "identity", aes(y = ..density..)) +
  geom_density(alpha = 0.5)+
  facet_wrap(vars(Test), scales = "free", ncol = 4) +
  theme_classic() +
  theme(
        axis.title.x=element_blank()) +
  labs(x = expression(paste(log[10], "CFU/mL or ", log[10], "MPN/L")),
       y = "Frequency")
#ggsave("Manuscript/Spore by parlor.tiff", height = 2, width = 8, units = "in", dpi = "retina")

FarmData %>% 
  filter(Test %in% c("MSC", "TSC", "PSC","BAB")) %>% 
  mutate(Farm = ifelse(CertYear <= 9, "New farm", "Old farm")) %>% 
  ggplot(aes(x = log10(Conc), fill = Farm)) +
  geom_histogram(alpha = 0.5, position = "identity", aes(y = ..density..)) +
  geom_density(alpha = 0.5)+
  facet_wrap(vars(Test), scales = "free", ncol = 4) +
  theme_classic() +
  theme(
        axis.title.x=element_blank()) +
  labs(x = expression(paste(log[10], "CFU/mL or ", log[10], "MPN/L")),
       y = "Frequency")
#ggsave("Manuscript/Spore by farm year.tiff", height = 2, width = 8, units = "in", dpi = "retina")

FarmData %>% 
  filter(Test %in% c("MSC", "TSC", "PSC","BAB")) %>% 
  mutate(Pasture = ifelse(PastureTime == 0, "w/o pasture time", "w/ pasture time")) %>% 
  ggplot(aes(x = log10(Conc), fill = Pasture)) +
  geom_histogram(alpha = 0.5, position = "identity", aes(y = ..density..)) +
  geom_density(alpha = 0.5)+
  facet_wrap(vars(Test), scales = "free", ncol = 4) +
  theme_classic() +
  theme(
        axis.title.x=element_blank()) +
  labs(x = expression(paste(log[10], "CFU/mL or ", log[10], "MPN/L")),
       y = "Frequency")
#ggsave("Manuscript/Spore by pasture time.tiff", height = 2, width = 8, units = "in", dpi = "retina")

```


## 3. Descriptive analysis
```{r, eval=FALSE}
testData = microTest %>% 
  mutate(Test = if_else(Test == "APC", "SPC", Test)) %>% 
  mutate(Notes = replace_na(Notes, "No notes")) %>% 
  mutate(Notes = tolower(Notes)) %>% 
  filter(Notes == "no notes") 

testData$Test = factor(testData$Test, levels = c("SPC", "PSC", "MSC", "TSC", "BAB"))

# summary stats
testData %>% 
  group_by(Test) %>% 
  summarise(mean_count = mean(log10(Conc)),
            sd_count = sd(log10(Conc)),
            n = n())

# check prevalence
testData %>% 
  filter(Test == "MSC") %>% 
  count(Conc == 0.125)

testData %>% 
  filter(Test == "BAB") %>% 
  count(Conc == 4.5)

testData %>% 
  filter(Test == "TSC") %>% 
  count(Conc == 0.125)

testData %>% 
  filter(Test == "PSC") %>% 
  count(Conc == 0.005)

# summary by farm
testData %>% 
  group_by(FarmID) %>%
  filter(Test == "SPC") %>% 
  summarise(mean_count = mean(log10(Conc)),
            sd_count = sd(log10(Conc)),
            n = n()) %>% 
  arrange(sd_count)

testData %>% 
  group_by(FarmID) %>%
  filter(Test == "SPC") %>% 
  summarise(mean_count = mean(log10(Conc)),
            sd_count = sd(log10(Conc)),
            n = n()) %>% 
  arrange(mean_count)

testData %>% 
  filter(Test == "MSC") %>% 
  group_by(FarmID) %>%
  summarise(mean_count = mean(log10(Conc)),
            sd_count = sd(log10(Conc)),
            n = n()) %>% 
  summarise(mean_mean = mean(mean_count),
            mean_sd = sd(mean_count),
            mean_max = max(mean_count),
            mean_min = min(mean_count),
            sd_mean = mean(sd_count, na.rm = T),
            sd_sd = sd(sd_count, na.rm = T),
            sd_max = max(sd_count, na.rm = T),
            sd_min = min(sd_count, na.rm = T))
## cv by type
testData %>% 
  filter(Test == "SPC") %>% 
  group_by(FarmID) %>%
  summarise(mean_count = mean(log10(Conc)),
            sd_count = sd(log10(Conc)),
            n = n()) %>% 
  summarise(mean_CV = sd(mean_count)/mean(mean_count),
            sd_CV = sd(sd_count, na.rm = T)/mean(sd_count, na.rm = T))

testData %>% 
  filter(Test == "MSC") %>% 
  group_by(FarmID) %>%
  summarise(mean_count = mean(log10(Conc)),
            sd_count = sd(log10(Conc)),
            n = n()) %>% 
  summarise(mean_CV = sd(mean_count)/mean(mean_count),
            sd_CV = sd(sd_count, na.rm = T)/mean(sd_count, na.rm = T))

testData %>% 
  filter(Test == "BAB") %>% 
  group_by(FarmID) %>%
  summarise(mean_count = mean(log10(Conc)),
            sd_count = sd(log10(Conc)),
            n = n()) %>% 
  summarise(mean_CV = sd(mean_count)/mean(mean_count),
            sd_CV = sd(sd_count, na.rm = T)/mean(sd_count, na.rm = T))

testData %>% 
  filter(Test == "TSC") %>% 
  group_by(FarmID) %>%
  summarise(mean_count = mean(log10(Conc)),
            sd_count = sd(log10(Conc)),
            n = n()) %>% 
  summarise(mean_CV = sd(mean_count)/mean(mean_count),
            sd_CV = sd(sd_count, na.rm = T)/mean(sd_count, na.rm = T))

testData %>% 
  filter(Test == "PSC") %>% 
  group_by(FarmID) %>%
  summarise(mean_count = mean(log10(Conc)),
            sd_count = sd(log10(Conc)),
            n = n()) %>% 
  summarise(mean_CV = sd(mean_count)/mean(mean_count),
            sd_CV = sd(sd_count, na.rm = T)/mean(sd_count, na.rm = T))

## plot for summary stats by farm
testData %>% 
  group_by(FarmID, Test) %>%
  summarise(mean_count = mean(log10(Conc)),
            sd_count = sd(log10(Conc))) %>% 
  ggplot(aes(x = mean_count, fill = Test)) +
  geom_histogram() +
  facet_wrap(vars(Test), scales = "free", ncol = 5) +
  theme_classic() +
  theme(legend.position = "none",
        axis.title.x=element_blank())
ggsave("Manuscript/mean by farm.tiff", height = 2, width = 8, units = "in", dpi = "retina")

testData %>% 
  group_by(FarmID, Test) %>%
  summarise(mean_count = mean(log10(Conc)),
            sd_count = sd(log10(Conc))) %>% 
  ggplot(aes(x = sd_count, fill = Test)) +
  geom_histogram() +
  facet_wrap(vars(Test), scales = "free", ncol = 5) +
  theme_classic() +
  theme(legend.position = "none",
        axis.title.x=element_blank())
ggsave("Manuscript/sd by farm.tiff", height = 2, width = 8, units = "in", dpi = "retina")

## correlation between spore types
testData %>%
  group_by(FarmID, Sampling, Test) %>%
  filter(n() > 1L) %>% 
  ungroup() %>% 
  select(FarmID, Sampling, Test, Conc)


## univariate plots
for (i in 1:ncol(FarmData)){
  var = colnames(FarmData)[i]
    ## Categorical variables
    if (class(FarmData[[var]]) != "numeric"){
          plot = ggplot(data = FarmData, aes(x = .data[[var]], y = log10(Conc+0.01), fill = .data[[var]]))+
            geom_boxplot()+
            facet_wrap(~Test)+
            theme_bw()+
            theme(axis.text.x=element_blank(),
                  axis.ticks.x=element_blank())
          
    ## Numeric variables
    } else {
          plot = ggplot(data = FarmData, aes(x = .data[[var]], y = log10(Conc+0.01)))+
            geom_point()+
            facet_wrap(~Test)+
            theme_bw()
    }
    #paste0("Summary plots/", var, ".tiff", by="") %>% ggsave()
}


FarmData %>% 
  ggplot(aes(x = Test, y = Conc, fill = Test)) +
  geom_boxplot() +
  scale_y_log10()

## spore count by type for each farm over sampling time
#FarmData %>% 
#  filter(Test == "BAB" & FarmID %in% c("R1", "R2")) %>% 
#  ggplot(aes(x = Sampling, y = log10(Conc), color = FarmID)) +
#  geom_point() +
#  facet_wrap(vars(FarmID)) +
#  theme_classic() +
#  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

## spore count by type 
FarmData %>% 
  filter(Test %in% c("SPC","MSC", "TSC", "PSC","BAB")) %>% 
  ggplot(aes(x = log10(Conc), fill = Test)) +
  geom_histogram() +
  facet_wrap(vars(Test), scales = "free", ncol = 5) +
  theme_classic() +
  theme(legend.position = "none",
        axis.title.x=element_blank()) +
  labs(x = expression(paste(log[10], "CFU/mL or ", log[10], "MPN/L")),
       y = "Frequency")
ggsave("Manuscript/Fig1.tiff", height = 2, width = 8, units = "in", dpi = "retina")


## summary plot for farm variables
char_vars <- sapply(FarmData, is.character)

# Initialize an empty list to store results
results_list <- list()

# Loop through the character variables and calculate percentages
for (var_name in names(FarmData)[char_vars]) {
  # Count occurrences of each level
  level_counts <- table(FarmData[, var_name])
  
  # Calculate percentages
  percentage <- (level_counts / sum(level_counts))
  
  # Create a data frame for the variable
  result_df <- data.frame(Level = names(level_counts), Percentage = percentage)
  
  # Add the result to the list
  results_list[[var_name]] <- result_df
}

# Display the results
#for (var_name in names(FarmData)[char_vars]) {
#  cat("Variable:", var_name, "\n")
#  print(results_list[[var_name]])
#  cat("\n")
#}
```

## 4. ML for explorative analysis 
### load packages
```{r}
library(tidymodels)
library(vip)
#library(learntidymodels)
library(patchwork)
library(ggforce)
library(tidytext)
library(themis)
library(pdp)
library(cowplot)
library(DALEXtra)
library(gridExtra)
```

### split dataset
```{r}
set.seed(1)

## Susbet data for MSC
MSCdata = FarmData %>% 
  filter(Test == "MSC") %>% 
  mutate(logConc = log10(Conc)) %>% 
  dplyr::select(-c(Conc, FarmID, SampleTime, Sampling, University, Coop, Loc))

MSC_Parlor = MSCdata %>% filter(Parlor == "Yes")

MSC_noParlor = MSCdata %>% filter(Parlor == "No")

MSC_Pasture = MSCdata %>% filter(PastureTime != 0)

MSC_noPasture = MSCdata %>% filter(PastureTime == 0)

MSC_newFarm = MSCdata %>% filter(CertYear <= 9)

MSC_oldFarm = MSCdata %>% filter(CertYear > 9)

## Susbet data for TSC
TSCdata = FarmData %>% 
  filter(Test == "TSC") %>% 
  mutate(logConc = log10(Conc)) %>% 
  dplyr::select(-c(Conc, FarmID, SampleTime, Sampling, University, Coop, Loc))

TSC_Parlor = TSCdata %>% filter(Parlor == "Yes")

TSC_noParlor = TSCdata %>% filter(Parlor == "No")

TSC_Pasture = TSCdata %>% filter(PastureTime != 0)

TSC_noPasture = TSCdata %>% filter(PastureTime == 0)

TSC_newFarm = TSCdata %>% filter(CertYear <= 9)

TSC_oldFarm = TSCdata %>% filter(CertYear > 9)

## Susbet data for PSC
PSCdata = FarmData %>% 
  filter(Test == "PSC") %>% 
  mutate(Pres = ifelse(Conc == 0.005, 0, 1),
         Pres = as.factor(Pres)) %>% 
  dplyr::select(-c(Conc, FarmID, SampleTime, Sampling, University, Coop, Loc))

PSC_Parlor = PSCdata %>% filter(Parlor == "Yes")

PSC_noParlor = PSCdata %>% filter(Parlor == "No")

PSC_Pasture = PSCdata %>% filter(PastureTime != 0)

PSC_noPasture = PSCdata %>% filter(PastureTime == 0)

PSC_newFarm = PSCdata %>% filter(CertYear <= 9)

PSC_oldFarm = PSCdata %>% filter(CertYear > 9)

## Susbet data for TSC
BABdata = FarmData %>% 
  filter(Test == "BAB") %>% 
  mutate(logConc = log10(Conc)) %>% 
  dplyr::select(-c(Conc, FarmID, SampleTime, Sampling, University, Coop, Loc))

BAB_Parlor = BABdata %>% filter(Parlor == "Yes")

BAB_noParlor = BABdata %>% filter(Parlor == "No")

BAB_Pasture = BABdata %>% filter(PastureTime != 0)

BAB_noPasture = BABdata %>% filter(PastureTime == 0)

BAB_newFarm = BABdata %>% filter(CertYear <= 9)

BAB_oldFarm = BABdata %>% filter(CertYear > 9)

```

### helper
```{r}
ggplot_pdp <- function(obj, x) {
  
  p <- 
    as_tibble(obj$agr_profiles) %>%
    mutate(`_label_` = stringr::str_remove(`_label_`, "^[^_]*_")) %>%
    ggplot(aes(`_x_`, `_yhat_`)) +
    geom_line(data = as_tibble(obj$cp_profiles),
              aes(x = {{ x }}, group = `_ids_`),
              size = 0.3, alpha = 0.05, color = "gray50") +
    theme(axis.text.x = element_text(size = 4)) + 
    theme_bw()
  
  num_colors <- n_distinct(obj$agr_profiles$`_label_`)
  
  if (num_colors > 1) {
    p <- p + geom_line(aes(color = `_label_`), size = 1.2, alpha = 0.8)
  } else {
    p <- p + geom_line(color = "midnightblue", size = 0.6, alpha = 0.8)
  }
  
  p
}


ggplot_pdp_cat <- function(obj, x) {
  
  p <- 
    as_tibble(obj$agr_profiles) %>%
    mutate(`_label_` = stringr::str_remove(`_label_`, "^[^_]*_")) %>%
    ggplot(aes(`_x_`, `_yhat_`)) +
    geom_point(data = as_tibble(obj$cp_profiles),
              aes(x = {{ x }}, group = `_ids_`),
              size = 0.3, alpha = 0.05, color = "gray50") +
    theme(axis.text.x = element_text(size = 4)) +
    theme_bw()
  
  num_colors <- n_distinct(obj$agr_profiles$`_label_`)
  
  if (num_colors > 1) {
    p <- p + geom_point(aes(color = `_label_`), size = 1.2, alpha = 0.8)
  } else {
    p <- p + geom_point(color = "midnightblue", size = 0.6, alpha = 0.8)
  }
  
  p
}
```

### MSC
```{r}
set.seed(1)

# create a list of data subsets
MSC_list = list(MSCdata, MSC_Parlor, MSC_noParlor, MSC_Pasture, MSC_noPasture, MSC_oldFarm, MSC_newFarm)
subset_names = c("All", "Parlor","noParlor","Pasture","noPasture","oldFarm", "newFarm")

# create empty data frames to store the model parameters, vip, and performance later
MSC_rs_paras = tibble()
MSC_vip = tibble(All = rep(NA,10),
                 Parlor = rep(NA,10),
                 noParlor = rep(NA,10),
                 Pasture = rep(NA,10),
                 noPasture= rep(NA,10),
                 oldFarm = rep(NA,10),
                 newFarm = rep(NA,10))
MSC_training_rs = tibble(All = NA,
                 Parlor = NA,
                 noParlor = NA,
                 Pasture = NA,
                 noPasture= NA,
                 oldFarm = NA,
                 newFarm = NA)
MSC_PCA_explained = data.frame(matrix(NA, ncol = 7, nrow = 5)) 
names(MSC_PCA_explained) = subset_names

# create recipe for data pre-processing 
for (i in 1:length(MSC_list)){
  MSC_recipe = recipe(logConc ~ ., data = MSC_list[[i]]) %>% 
    step_zv(all_predictors()) %>% 
    step_normalize(all_numeric_predictors()) %>%
    step_pca(c("tempmax","tempmin","temp","humidity","precip","precipcover","windgust",      
             "windspeed","solarradiation","tempmax_1d","tempmin_1d","temp_1d","humidity_1d",
             "precip_1d", "precipcover_1d", "windgust_1d", "windspeed_1d", "solarradiation_1d","tempmax_2d",
             "tempmin_2d","temp_2d", "humidity_2d","precip_2d","precipcover_2d","windgust_2d","windspeed_2d",
             "solarradiation_2d", "tempmax_3d","tempmin_3d", "temp_3d",  "humidity_3d", "precip_3d",
             "precipcover_3d", "windgust_3d", "windspeed_3d","solarradiation_3d"), num_comp = 5) %>%
    step_dummy(all_nominal_predictors(), one_hot = FALSE) %>% 
    step_nzv(all_predictors(), freq_cut = 85/15) 

  # set up specification of algorithm
  rf_spec = rand_forest(
     trees = 1000,
     min_n = tune(),
     mtry = tune()) %>% 
     set_engine("ranger") %>% 
     set_mode("regression")
  
  dimension = MSC_recipe %>% prep() %>% bake(NULL) %>% dim()
  nVar = dimension[2]
  
  # set up hyperparameter configuration
  rf_grid = grid_max_entropy(
    min_n(c(2L, 10L)),
    mtry(c(1L, nVar - 1)),
    size = 40
  )
  
  # create workflow by combining recipe and rf specification
  MSC_wf = workflow() %>% 
    add_recipe(MSC_recipe) %>% 
    add_model(rf_spec)
  
  # set up cross-validation
  MSC_folds = vfold_cv(MSC_list[[i]], strata = logConc, v = 3, repeats = 5)
  
  # train and tune the model
  MSC_rs = tune_grid(
    MSC_wf,
    MSC_folds,
    grid = rf_grid,
    metrics = metric_set(rsq),
    control = control_grid(verbose = FALSE)
  )
  
  # store the best model parameters
  best_rs = show_best(MSC_rs, metric = "rsq")
  best_rs_paras = best_rs %>% slice(1) %>% mutate(dataset = subset_names[i])
  MSC_rs_paras = bind_rows(best_rs_paras, MSC_rs_paras)
  
  # select the final model
  choose_tree = MSC_rs %>% select_best(metric = "rsq")
  
  final_model = MSC_wf %>% 
    finalize_workflow(choose_tree) 

  # fit the model to the original data and display results
  final_fit = fit(final_model, data = MSC_list[[i]])
  predictions = predict(final_fit, MSC_list[[i]])
  results = bind_cols(MSC_list[[i]], predictions)
  model_rsq = rsq(results, truth = logConc, estimate = .pred)
  print(paste0("rsq is ", model_rsq$.estimate," for ", subset_names[[i]]))
  MSC_training_rs[[i]] = model_rsq
  
  # create VIPs
  imp_spec = rf_spec %>% 
    finalize_model(select_best(MSC_rs, metric = "rsq")) %>% 
    set_engine("ranger", importance = "permutation")

  vip_plot = workflow() %>% 
      add_recipe(MSC_recipe) %>% 
      add_model(imp_spec) %>% 
      fit(MSC_list[[i]]) %>% 
      extract_fit_parsnip() %>% 
      vip(geom = "point", num_features = 10)
  
  file_name = paste0("Figure/VIP/MSC/MSC_VIP_", subset_names[i], ".tiff")
  ggsave(file_name, height = 4, width = 8, units = "in", dpi = "retina")
  
  # Create PDPs
  vip_features = vip_plot$data$Variable
  vip_features = vip_features %>% 
    sub("_.*", "", .) %>% 
    setdiff(., c("PC1", "PC2", "PC3", "PC4", "PC5"))
  
  # Loop through variable names and categorize based on type in the dataset
  numVar <- character()
  catVar <- character()


  for (var in vip_features) {
    if (is.numeric(MSC_list[[i]][[var]])) {
      numVar = c(numVar, var)
    } else {
      catVar = c(catVar, var)
    }
  }
  
  model_explainer = explain_tidymodels(
    final_fit,
    data = MSC_list[[i]],
    y = MSC_list[[i]]$logConc,
    verbose = F)
  
  numPlots = list()
  for (j in 1:length(numVar)) {
    profile = model_profile(model_explainer, N = NULL, variables = numVar[j])
    
    pdp = ggplot_pdp(profile, !!as.name(numVar[j])) +
      labs(x = numVar[j],
           y = "logConc",
           color = NULL)
    
    file_name = paste0("Figure/PDP/By spore type/MSC/MSC_pdp_", subset_names[i], "_", numVar[j], ".tiff")
    ggsave(file_name, height = 4, width = 4, units = "in", dpi = "retina")
    
    numPlots[[j]] = pdp
    
  }
  
  numPlots_grid = gridExtra::grid.arrange(grobs = numPlots, ncol = 3)
  file_name = paste0("Figure/PDP/By spore type/MSC/NumVars_MSC_", subset_names[i], ".pdf")
  ggsave(file_name, numPlots_grid, 
         height = 4, width = 8, units = "in", dpi = "retina")
  
  
  catPlots = list()
  for (k in 1:length(catVar)) {
    profile = model_profile(model_explainer, N = NULL, variables = catVar[k])
    
    pdp = ggplot_pdp_cat(profile, !!as.name(catVar[k])) +
      labs(x = catVar[k],
           y = "logConc",
           color = NULL)+
      theme(axis.text.x = element_text(size = 4))
    
    file_name = paste0("Figure/PDP/By spore type/MSC/MSC_pdp_", subset_names[i], "_", catVar[k], ".tiff")
    ggsave(file_name, height = 4, width = 4, units = "in", dpi = "retina")
    
    catPlots[[k]] = pdp
    
  }
  
  catPlots_grid = gridExtra::grid.arrange(grobs = catPlots, ncol = 3)
  file_name = paste0("Figure/PDP/By spore type/MSC/CatVars_MSC_", subset_names[i], ".pdf")
  ggsave(file_name, catPlots_grid,
         height = 4, width = 8, units = "in", dpi = "retina")

  
  
  # Create VIP tibble
  MSC_vip[[i]] = vip_plot$data$Variable
  
  pca_prep = prep(MSC_recipe)

  tidied_pca = tidy(pca_prep, 3)

  tidied_pca %>%
    filter(component %in% paste0("PC", 1:5)) %>%
    mutate(component = fct_inorder(component)) %>%
    ggplot(aes(value, terms, fill = terms)) +
    geom_col(show.legend = FALSE) +
    facet_wrap(~component, nrow = 1) +
    labs(y = NULL) +
    theme(axis.text.y = element_text(size = 5))
  file_name = paste0("Figure/PCA/MSC/MSC_PCA_", subset_names[i], ".tiff")
  ggsave(file_name, height = 4, width = 8, units = "in", dpi = "retina")

  tidied_pca %>%
    filter(component %in% paste0("PC", 1:5)) %>%
    group_by(component) %>%
    top_n(8, abs(value)) %>%
    ungroup() %>%
    mutate(terms = reorder_within(terms, abs(value), component)) %>%
    ggplot(aes(abs(value), terms, fill = value > 0)) +
    geom_col() +
    facet_wrap(~component, scales = "free_y") +
    scale_y_reordered() +
    labs(
      x = "Absolute value of contribution",
      y = NULL, fill = "Positive?"
    )
    file_name = paste0("Figure/PCA/MSC/MSC_PCA_top_", subset_names[i], ".tiff")
    ggsave(file_name, height = 4, width = 8, units = "in", dpi = "retina")
    
    sdev = pca_prep$steps[[3]]$res$sdev
    percent_variation = sdev^2 / sum(sdev^2)
    var_df = data.frame(PC=paste0("PC",1:length(sdev)),
                       var_explained=percent_variation,
                       stringsAsFactors = FALSE)
    
    top5 = var_df[1:5, 2]
    MSC_PCA_explained[,i] = top5    

}

MSC_rs_paras
MSC_PCA_explained
MSC_vip

save(MSC_rs_paras, file = "Results/MSC_results.RData")
save(MSC_PCA_explained, file = "Results/MSC_PCA_results.RData")

```

### TSC
```{r}
set.seed(1)

TSC_list = list(TSCdata, TSC_Parlor, TSC_noParlor, TSC_Pasture, TSC_noPasture, TSC_oldFarm, TSC_newFarm)
subset_names = c("All", "Parlor","noParlor","Pasture","noPasture","oldFarm", "newFarm")
TSC_rs_paras = tibble()
TSC_vip = tibble(All = rep(NA,10),
                 Parlor = rep(NA,10),
                 noParlor = rep(NA,10),
                 Pasture = rep(NA,10),
                 noPasture= rep(NA,10),
                 oldFarm = rep(NA,10),
                 newFarm = rep(NA,10))
TSC_training_rs = tibble(All = NA,
                 Parlor = NA,
                 noParlor = NA,
                 Pasture = NA,
                 noPasture= NA,
                 oldFarm = NA,
                 newFarm = NA)
TSC_PCA_explained = data.frame(matrix(NA, ncol = 7, nrow = 5)) 
names(TSC_PCA_explained) = subset_names

## Model formula
for (i in 1:length(TSC_list)){
  TSC_recipe = recipe(logConc ~ ., data = TSC_list[[i]]) %>% 
    step_zv(all_predictors()) %>% 
    step_normalize(all_numeric_predictors()) %>%
    step_pca(c("tempmax","tempmin","temp","humidity","precip","precipcover","windgust",      
             "windspeed","solarradiation","tempmax_1d","tempmin_1d","temp_1d","humidity_1d",
             "precip_1d", "precipcover_1d", "windgust_1d", "windspeed_1d", "solarradiation_1d","tempmax_2d",
             "tempmin_2d","temp_2d", "humidity_2d","precip_2d","precipcover_2d","windgust_2d","windspeed_2d",
             "solarradiation_2d", "tempmax_3d","tempmin_3d", "temp_3d",  "humidity_3d", "precip_3d",
             "precipcover_3d", "windgust_3d", "windspeed_3d","solarradiation_3d"), num_comp = 5) %>%
    step_dummy(all_nominal_predictors(), one_hot = FALSE) %>% 
    step_nzv(all_predictors(), freq_cut = 85/15) 

  rf_spec = rand_forest(
     trees = 1000,
     min_n = tune(),
     mtry = tune()) %>% 
     set_engine("ranger") %>% 
     set_mode("regression")
  
  dimension = TSC_recipe %>% prep() %>% bake(NULL) %>% dim()
  nVar = dimension[2]
  
  rf_grid = grid_max_entropy(
    min_n(c(2L, 10L)),
    mtry(c(1L, nVar - 1)),
    size = 40
  )
  
  TSC_wf = workflow() %>% 
    add_recipe(TSC_recipe) %>% 
    add_model(rf_spec)
  
  TSC_folds = vfold_cv(TSC_list[[i]], strata = logConc, v = 3, repeats = 5)
  
  TSC_rs = tune_grid(
    TSC_wf,
    TSC_folds,
    grid = rf_grid,
    metrics = metric_set(rsq),
    control = control_grid(verbose = FALSE)
  )
  
  best_rs = show_best(TSC_rs, metric = "rsq")
  best_rs_paras = best_rs %>% slice(1) %>% mutate(dataset = subset_names[i])
  TSC_rs_paras = bind_rows(best_rs_paras, TSC_rs_paras)
  
  # select the final model
  choose_tree = TSC_rs %>% select_best(metric = "rsq")
  
  final_model = TSC_wf %>% 
    finalize_workflow(choose_tree) 

  final_fit = fit(final_model, data = TSC_list[[i]])
  predictions = predict(final_fit, TSC_list[[i]])
  results = bind_cols(TSC_list[[i]], predictions)
  model_rsq = rsq(results, truth = logConc, estimate = .pred)
  print(paste0("rsq is ", model_rsq$.estimate," for ", subset_names[[i]]))
  TSC_training_rs[[i]] = model_rsq
  
  
  # create VIPs
  imp_spec = rf_spec %>% 
    finalize_model(select_best(TSC_rs, metric = "rsq")) %>% 
    set_engine("ranger", importance = "permutation")

  vip_plot = workflow() %>% 
      add_recipe(TSC_recipe) %>% 
      add_model(imp_spec) %>% 
      fit(TSC_list[[i]]) %>% 
      extract_fit_parsnip() %>% 
      vip(geom = "point", num_features = 10)
  
  file_name = paste0("Figure/VIP/TSC/TSC_VIP_", subset_names[i], ".tiff")
  ggsave(file_name, height = 4, width = 8, units = "in", dpi = "retina")
  
  # Create PDPs
  vip_features = vip_plot$data$Variable
  vip_features = vip_features %>% 
    sub("_.*", "", .) %>% 
    setdiff(., c("PC1", "PC2", "PC3", "PC4", "PC5"))
  
  # Loop through variable names and categorize based on type in the dataset
  numVar <- character()
  catVar <- character()


  for (var in vip_features) {
    if (is.numeric(TSC_list[[i]][[var]])) {
      numVar = c(numVar, var)
    } else  {
      catVar = c(catVar, var)
    }
  }
  
  model_explainer = explain_tidymodels(
    final_fit,
    data = TSC_list[[i]],
    y = TSC_list[[i]]$logConc,
    verbose = F)
  
  numPlots = list()
  for (j in 1:length(numVar)) {
    profile = model_profile(model_explainer, N = NULL, variables = numVar[j])
    
    pdp = ggplot_pdp(profile, !!as.name(numVar[j])) +
      labs(x = numVar[j],
           y = "logConc",
           color = NULL)
    
    file_name = paste0("Figure/PDP/By spore type/TSC/TSC_pdp_", subset_names[i], "_", numVar[j], ".tiff")
    ggsave(file_name, height = 4, width = 4, units = "in", dpi = "retina")
    
    numPlots[[j]] = pdp
    
  }
  
  numPlots_grid = gridExtra::grid.arrange(grobs = numPlots, ncol = 3)
  file_name = paste0("Figure/PDP/By spore type/TSC/NumVars_TSC_", subset_names[i], ".pdf")
  ggsave(file_name, numPlots_grid, 
         height = 4, width = 8, units = "in", dpi = "retina")
  
  
  catPlots = list()
  for (k in 1:length(catVar)) {
    profile = model_profile(model_explainer, N = NULL, variables = catVar[k])
    
    pdp = ggplot_pdp_cat(profile, !!as.name(catVar[k])) +
      labs(x = catVar[k],
           y = "logConc",
           color = NULL)+
      theme(axis.text.x = element_text(size = 4))
    
    file_name = paste0("Figure/PDP/By spore type/TSC/TSC_pdp_", subset_names[i], "_", catVar[k], ".tiff")
    ggsave(file_name, height = 4, width = 4, units = "in", dpi = "retina")
    
    catPlots[[k]] = pdp
    
  }
  
  catPlots_grid = gridExtra::grid.arrange(grobs = catPlots, ncol = 3)
  file_name = paste0("Figure/PDP/By spore type/TSC/CatVars_TSC_", subset_names[i], ".pdf")
  ggsave(file_name, catPlots_grid,
         height = 4, width = 8, units = "in", dpi = "retina")

  
  
  # Create VIP
  TSC_vip[[i]] = vip_plot$data$Variable
  
  pca_prep = prep(TSC_recipe)

  tidied_pca = tidy(pca_prep, 3)

  tidied_pca %>%
    filter(component %in% paste0("PC", 1:5)) %>%
    mutate(component = fct_inorder(component)) %>%
    ggplot(aes(value, terms, fill = terms)) +
    geom_col(show.legend = FALSE) +
    facet_wrap(~component, nrow = 1) +
    labs(y = NULL) +
    theme(axis.text.y = element_text(size = 5))
  file_name = paste0("Figure/PCA/TSC/TSC_PCA_", subset_names[i], ".tiff")
  ggsave(file_name, height = 4, width = 8, units = "in", dpi = "retina")

  tidied_pca %>%
    filter(component %in% paste0("PC", 1:5)) %>%
    group_by(component) %>%
    top_n(8, abs(value)) %>%
    ungroup() %>%
    mutate(terms = reorder_within(terms, abs(value), component)) %>%
    ggplot(aes(abs(value), terms, fill = value > 0)) +
    geom_col() +
    facet_wrap(~component, scales = "free_y") +
    scale_y_reordered() +
    labs(
      x = "Absolute value of contribution",
      y = NULL, fill = "Positive?"
    )
    file_name = paste0("Figure/PCA/TSC/TSC_PCA_top_", subset_names[i], ".tiff")
    ggsave(file_name, height = 4, width = 8, units = "in", dpi = "retina")
    
    sdev = pca_prep$steps[[3]]$res$sdev
    percent_variation = sdev^2 / sum(sdev^2)
    var_df = data.frame(PC=paste0("PC",1:length(sdev)),
                       var_explained=percent_variation,
                       stringsAsFactors = FALSE)
    
    top5 = var_df[1:5, 2]
    TSC_PCA_explained[,i] = top5    

}

TSC_rs_paras
TSC_PCA_explained
TSC_vip

save(TSC_rs_paras, file = "Results/TSC_results.RData")
save(TSC_PCA_explained, file = "Results/TSC_PCA_results.RData")
```


### PSC
```{r}
set.seed(1)

PSC_list = list(PSCdata, PSC_Parlor, PSC_noParlor, PSC_Pasture, PSC_noPasture, PSC_oldFarm, PSC_newFarm)
subset_names = c("All", "Parlor","noParlor","Pasture","noPasture","oldFarm", "newFarm")
PSC_rs_paras = tibble()
PSC_vip = tibble(All = rep(NA,10),
                 Parlor = rep(NA,10),
                 noParlor = rep(NA,10),
                 Pasture = rep(NA,10),
                 noPasture= rep(NA,10),
                 oldFarm = rep(NA,10),
                 newFarm = rep(NA,10))
PSC_training_rs = tibble(All = rep(NA,3),
                 Parlor = rep(NA,3),
                 noParlor = rep(NA,3),
                 Pasture = rep(NA,3),
                 noPasture= rep(NA,3),
                 oldFarm = rep(NA,3),
                 newFarm = rep(NA,3))
PSC_PCA_explained = data.frame(matrix(NA, ncol = 7, nrow = 5)) 
names(PSC_PCA_explained) = subset_names

## Model formula
for (i in 1:length(PSC_list)){
  PSC_recipe = recipe(Pres ~ ., data = PSC_list[[i]]) %>% 
    step_zv(all_predictors()) %>% 
    step_normalize(all_numeric_predictors()) %>%
    step_pca(c("tempmax","tempmin","temp","humidity","precip","precipcover","windgust",      
             "windspeed","solarradiation","tempmax_1d","tempmin_1d","temp_1d","humidity_1d",
             "precip_1d", "precipcover_1d", "windgust_1d", "windspeed_1d", "solarradiation_1d","tempmax_2d",
             "tempmin_2d","temp_2d", "humidity_2d","precip_2d","precipcover_2d","windgust_2d","windspeed_2d",
             "solarradiation_2d", "tempmax_3d","tempmin_3d", "temp_3d",  "humidity_3d", "precip_3d",
             "precipcover_3d", "windgust_3d", "windspeed_3d","solarradiation_3d"), num_comp = 5) %>%
    step_dummy(all_nominal_predictors(), one_hot = FALSE) %>% 
    step_nzv(all_predictors(), freq_cut = 85/15) %>% 
    step_smotenc(Pres)

  rf_spec = rand_forest(
     trees = 1000,
     min_n = tune(),
     mtry = tune()) %>% 
     set_engine("ranger") %>% 
     set_mode("classification")
  
  dimension = PSC_recipe %>% prep() %>% bake(NULL) %>% dim()
  nVar = dimension[2]
  
  rf_grid = grid_max_entropy(
    min_n(c(2L, 10L)),
    mtry(c(1L, nVar - 1)),
    size = 40
  )
  
  PSC_wf = workflow() %>% 
    add_recipe(PSC_recipe) %>% 
    add_model(rf_spec)
  
  PSC_folds = vfold_cv(PSC_list[[i]], strata = Pres, v = 3, repeats = 5)
  
  PSC_rs = tune_grid(
    PSC_wf,
    PSC_folds,
    grid = rf_grid,
    metrics = metric_set(roc_auc, accuracy, sensitivity, specificity),
    control = control_grid(verbose = FALSE)
  )
  
  best_rs = show_best(PSC_rs, metric = "accuracy")
  best_rs_paras = best_rs %>% slice(1) %>% mutate(dataset = subset_names[i])
  PSC_rs_paras = bind_rows(best_rs_paras, PSC_rs_paras)
  
  # select the final model
  choose_tree = PSC_rs %>% select_best(metric = "accuracy")
  
  final_model = PSC_wf %>% 
    finalize_workflow(choose_tree) 

  final_fit = fit(final_model, data = PSC_list[[i]])
  predictions = predict(final_fit, PSC_list[[i]])
  results = bind_cols(PSC_list[[i]], predictions)
  acc = accuracy(results, truth = Pres, estimate = .pred_class)
  se = sensitivity(results, truth = Pres, estimate = .pred_class)
  sp = specificity(results, truth = Pres, estimate = .pred_class)
  print(paste0("se is ", se$.estimate, " and sp is ", sp$.estimate, " for ", subset_names[[i]]))
  PSC_training_rs[[i]] = c(acc$.estimate, se$.estimate, sp$.estimate)
  
  # create VIPs
  imp_spec = rf_spec %>% 
    finalize_model(select_best(PSC_rs, metric = "accuracy")) %>% 
    set_engine("ranger", importance = "permutation")

  vip_plot = workflow() %>% 
      add_recipe(PSC_recipe) %>% 
      add_model(imp_spec) %>% 
      fit(PSC_list[[i]]) %>% 
      extract_fit_parsnip() %>% 
      vip(geom = "point", num_features = 10)
  
  file_name = paste0("Figure/VIP/PSC/PSC_VIP_", subset_names[i], ".tiff")
  ggsave(file_name, height = 4, width = 8, units = "in", dpi = "retina")
  
  # Create PDPs
  vip_features = vip_plot$data$Variable
  vip_features = vip_features %>% 
    sub("_.*", "", .) %>% 
    setdiff(., c("PC1", "PC2", "PC3", "PC4", "PC5"))
  
  # Loop through variable names and categorize based on type in the dataset
  numVar <- character()
  catVar <- character()


  for (var in vip_features) {
    if (is.numeric(PSC_list[[i]][[var]])) {
      numVar = c(numVar, var)
    } else  {
      catVar = c(catVar, var)
    }
  }
  
  model_explainer = explain_tidymodels(
    final_fit,
    data = PSC_list[[i]],
    y = PSC_list[[i]]$logConc,
    verbose = F)
  
  numPlots = list()
  for (j in 1:length(numVar)) {
    profile = model_profile(model_explainer, N = NULL, variables = numVar[j])
    
    pdp = ggplot_pdp(profile, !!as.name(numVar[j])) +
      labs(x = numVar[j],
           y = "Likelihood of Presence",
           color = NULL)
    
    file_name = paste0("Figure/PDP/By spore type/PSC/PSC_pdp_", subset_names[i], "_", numVar[j], ".tiff")
    ggsave(file_name, height = 4, width = 4, units = "in", dpi = "retina")
    
    numPlots[[j]] = pdp
    
  }
  
  numPlots_grid = gridExtra::grid.arrange(grobs = numPlots, ncol = 3)
  file_name = paste0("Figure/PDP/By spore type/PSC/NumVars_PSC_", subset_names[i], ".pdf")
  ggsave(file_name, numPlots_grid, 
         height = 4, width = 8, units = "in", dpi = "retina")
  
  
  catPlots = list()
  for (k in 1:length(catVar)) {
    profile = model_profile(model_explainer, N = NULL, variables = catVar[k])
    
    pdp = ggplot_pdp_cat(profile, !!as.name(catVar[k])) +
      labs(x = catVar[k],
           y = "Likelihood of Presence",
           color = NULL)+
      theme(axis.text.x = element_text(size = 4))
    
    file_name = paste0("Figure/PDP/By spore type/PSC/PSC_pdp_", subset_names[i], "_", catVar[k], ".tiff")
    ggsave(file_name, height = 4, width = 4, units = "in", dpi = "retina")
    
    catPlots[[k]] = pdp
    
  }
  
  catPlots_grid = gridExtra::grid.arrange(grobs = catPlots, ncol = 3)
  file_name = paste0("Figure/PDP/By spore type/PSC/CatVars_PSC_", subset_names[i], ".pdf")
  ggsave(file_name, catPlots_grid,
         height = 4, width = 8, units = "in", dpi = "retina")

  
  
  # Create VIP
  PSC_vip[[i]] = vip_plot$data$Variable
  
  pca_prep = prep(PSC_recipe)

  tidied_pca = tidy(pca_prep, 3)

  tidied_pca %>%
    filter(component %in% paste0("PC", 1:5)) %>%
    mutate(component = fct_inorder(component)) %>%
    ggplot(aes(value, terms, fill = terms)) +
    geom_col(show.legend = FALSE) +
    facet_wrap(~component, nrow = 1) +
    labs(y = NULL) +
    theme(axis.text.y = element_text(size = 5))
  file_name = paste0("Figure/PCA/PSC/PSC_PCA_", subset_names[i], ".tiff")
  ggsave(file_name, height = 4, width = 8, units = "in", dpi = "retina")

  tidied_pca %>%
    filter(component %in% paste0("PC", 1:5)) %>%
    group_by(component) %>%
    top_n(8, abs(value)) %>%
    ungroup() %>%
    mutate(terms = reorder_within(terms, abs(value), component)) %>%
    ggplot(aes(abs(value), terms, fill = value > 0)) +
    geom_col() +
    facet_wrap(~component, scales = "free_y") +
    scale_y_reordered() +
    labs(
      x = "Absolute value of contribution",
      y = NULL, fill = "Positive?"
    )
    file_name = paste0("Figure/PCA/PSC/PSC_PCA_top_", subset_names[i], ".tiff")
    ggsave(file_name, height = 4, width = 8, units = "in", dpi = "retina")
    
    sdev = pca_prep$steps[[3]]$res$sdev
    percent_variation = sdev^2 / sum(sdev^2)
    var_df = data.frame(PC=paste0("PC",1:length(sdev)),
                       var_explained=percent_variation,
                       stringsAsFactors = FALSE)
    
    top5 = var_df[1:5, 2]
    PSC_PCA_explained[,i] = top5    

}

PSC_rs_paras
PSC_PCA_explained
PSC_vip

save(PSC_rs_paras, file = "Results/PSC_results.RData")
save(PSC_PCA_explained, file = "Results/PSC_PCA_results.RData")
```



### BAB
```{r}
set.seed(1)

BAB_list = list(BABdata, BAB_Parlor, BAB_noParlor, BAB_Pasture, BAB_noPasture, BAB_oldFarm, BAB_newFarm)
subset_names = c("All", "Parlor","noParlor","Pasture","noPasture","oldFarm", "newFarm")
BAB_rs_paras = tibble()
BAB_vip = tibble(All = rep(NA,10),
                 Parlor = rep(NA,10),
                 noParlor = rep(NA,10),
                 Pasture = rep(NA,10),
                 noPasture= rep(NA,10),
                 oldFarm = rep(NA,10),
                 newFarm = rep(NA,10))
BAB_training_rs = tibble(All = NA,
                 Parlor = NA,
                 noParlor = NA,
                 Pasture = NA,
                 noPasture= NA,
                 oldFarm = NA,
                 newFarm = NA)
BAB_PCA_explained = data.frame(matrix(NA, ncol = 7, nrow = 5)) 
names(BAB_PCA_explained) = subset_names

## Model formula
for (i in 1:length(BAB_list)){
  BAB_recipe = recipe(logConc ~ ., data = BAB_list[[i]]) %>% 
    step_zv(all_predictors()) %>% 
    step_normalize(all_numeric_predictors()) %>%
    step_pca(c("tempmax","tempmin","temp","humidity","precip","precipcover","windgust",      
             "windspeed","solarradiation","tempmax_1d","tempmin_1d","temp_1d","humidity_1d",
             "precip_1d", "precipcover_1d", "windgust_1d", "windspeed_1d", "solarradiation_1d","tempmax_2d",
             "tempmin_2d","temp_2d", "humidity_2d","precip_2d","precipcover_2d","windgust_2d","windspeed_2d",
             "solarradiation_2d", "tempmax_3d","tempmin_3d", "temp_3d",  "humidity_3d", "precip_3d",
             "precipcover_3d", "windgust_3d", "windspeed_3d","solarradiation_3d"), num_comp = 5) %>%
    step_dummy(all_nominal_predictors(), one_hot = FALSE) %>% 
    step_nzv(all_predictors(), freq_cut = 85/15) 

  rf_spec = rand_forest(
     trees = 1000,
     min_n = tune(),
     mtry = tune()) %>% 
     set_engine("ranger") %>% 
     set_mode("regression")
  
  dimension = BAB_recipe %>% prep() %>% bake(NULL) %>% dim()
  nVar = dimension[2]
  
  rf_grid = grid_max_entropy(
    min_n(c(2L, 10L)),
    mtry(c(1L, nVar - 2)),
    size = 40
  )
  
  BAB_wf = workflow() %>% 
    add_recipe(BAB_recipe) %>% 
    add_model(rf_spec)
  
  BAB_folds = vfold_cv(BAB_list[[i]], strata = logConc, v = 3, repeats = 5)
  
  BAB_rs = tune_grid(
    BAB_wf,
    BAB_folds,
    grid = rf_grid,
    metrics = metric_set(rsq),
    control = control_grid(verbose = FALSE)
  )
  
  best_rs = show_best(BAB_rs, metric = "rsq")
  best_rs_paras = best_rs %>% slice(1) %>% mutate(dataset = subset_names[i])
  BAB_rs_paras = bind_rows(best_rs_paras, BAB_rs_paras)
  
  # select the final model
  choose_tree = BAB_rs %>% select_best(metric = "rsq")
  
  final_model = BAB_wf %>% 
    finalize_workflow(choose_tree) 

  final_fit = fit(final_model, data = BAB_list[[i]])
  predictions = predict(final_fit, BAB_list[[i]])
  results = bind_cols(BAB_list[[i]], predictions)
  model_rsq = rsq(results, truth = logConc, estimate = .pred)
  print(paste0("rsq is ", model_rsq$.estimate," for ", subset_names[[i]]))
  BAB_training_rs[[i]] = model_rsq
  
  # create VIPs
  imp_spec = rf_spec %>% 
    finalize_model(select_best(BAB_rs, metric = "rsq")) %>% 
    set_engine("ranger", importance = "permutation")

  vip_plot = workflow() %>% 
      add_recipe(BAB_recipe) %>% 
      add_model(imp_spec) %>% 
      fit(BAB_list[[i]]) %>% 
      extract_fit_parsnip() %>% 
      vip(geom = "point", num_features = 10)
  
  file_name = paste0("Figure/VIP/BAB/BAB_VIP_", subset_names[i], ".tiff")
  ggsave(file_name, height = 4, width = 8, units = "in", dpi = "retina")
  
  # Create PDPs
  vip_features = vip_plot$data$Variable
  vip_features = vip_features %>% 
    sub("_.*", "", .) %>% 
    setdiff(., c("PC1", "PC2", "PC3", "PC4", "PC5"))
  
  # Loop through variable names and categorize based on type in the dataset
  numVar <- character()
  catVar <- character()


  for (var in vip_features) {
    if (is.numeric(BAB_list[[i]][[var]])) {
      numVar = c(numVar, var)
    } else {
      catVar = c(catVar, var)
    }
  }
  
  model_explainer = explain_tidymodels(
    final_fit,
    data = BAB_list[[i]],
    y = BAB_list[[i]]$logConc,
    verbose = F)
  
  numPlots = list()
  for (j in 1:length(numVar)) {
    profile = model_profile(model_explainer, N = NULL, variables = numVar[j])
    
    pdp = ggplot_pdp(profile, !!as.name(numVar[j])) +
      labs(x = numVar[j],
           y = "logConc",
           color = NULL)
    
    file_name = paste0("Figure/PDP/By spore type/BAB/BAB_pdp_", subset_names[i], "_", numVar[j], ".tiff")
    ggsave(file_name, height = 4, width = 4, units = "in", dpi = "retina")
    
    numPlots[[j]] = pdp
    
  }
  
  numPlots_grid = gridExtra::grid.arrange(grobs = numPlots, ncol = 3)
  file_name = paste0("Figure/PDP/By spore type/BAB/NumVars_BAB_", subset_names[i], ".pdf")
  ggsave(file_name, numPlots_grid, 
         height = 4, width = 8, units = "in", dpi = "retina")
  
  
  catPlots = list()
  for (k in 1:length(catVar)) {
    profile = model_profile(model_explainer, N = NULL, variables = catVar[k])
    
    pdp = ggplot_pdp_cat(profile, !!as.name(catVar[k])) +
      labs(x = catVar[k],
           y = "logConc",
           color = NULL)+
      theme(axis.text.x = element_text(size = 4))
    
    file_name = paste0("Figure/PDP/By spore type/BAB/BAB_pdp_", subset_names[i], "_", catVar[k], ".tiff")
    ggsave(file_name, height = 4, width = 4, units = "in", dpi = "retina")
    
    catPlots[[k]] = pdp
    
  }
  
  catPlots_grid = gridExtra::grid.arrange(grobs = catPlots, ncol = 3)
  file_name = paste0("Figure/PDP/By spore type/BAB/CatVars_BAB_", subset_names[i], ".pdf")
  ggsave(file_name, catPlots_grid,
         height = 4, width = 8, units = "in", dpi = "retina")

  
  # Create VIP
  BAB_vip[[i]] = vip_plot$data$Variable
  
  pca_prep = prep(BAB_recipe)

  tidied_pca = tidy(pca_prep, 3)

  tidied_pca %>%
    filter(component %in% paste0("PC", 1:5)) %>%
    mutate(component = fct_inorder(component)) %>%
    ggplot(aes(value, terms, fill = terms)) +
    geom_col(show.legend = FALSE) +
    facet_wrap(~component, nrow = 1) +
    labs(y = NULL) +
    theme(axis.text.y = element_text(size = 5))
  file_name = paste0("Figure/PCA/BAB/BAB_PCA_", subset_names[i], ".tiff")
  ggsave(file_name, height = 4, width = 8, units = "in", dpi = "retina")

  tidied_pca %>%
    filter(component %in% paste0("PC", 1:5)) %>%
    group_by(component) %>%
    top_n(8, abs(value)) %>%
    ungroup() %>%
    mutate(terms = reorder_within(terms, abs(value), component)) %>%
    ggplot(aes(abs(value), terms, fill = value > 0)) +
    geom_col() +
    facet_wrap(~component, scales = "free_y") +
    scale_y_reordered() +
    labs(
      x = "Absolute value of contribution",
      y = NULL, fill = "Positive?"
    )
    file_name = paste0("Figure/PCA/BAB/BAB_PCA_top_", subset_names[i], ".tiff")
    ggsave(file_name, height = 4, width = 8, units = "in", dpi = "retina")
    
    sdev = pca_prep$steps[[3]]$res$sdev
    percent_variation = sdev^2 / sum(sdev^2)
    var_df = data.frame(PC=paste0("PC",1:length(sdev)),
                       var_explained=percent_variation,
                       stringsAsFactors = FALSE)
    
    top5 = var_df[1:5, 2]
    BAB_PCA_explained[,i] = top5    

}

BAB_rs_paras
BAB_PCA_explained
BAB_vip

save(BAB_rs_paras, file = "Results/BAB_results.RData")
save(BAB_PCA_explained, file = "Results/BAB_PCA_results.RData")
```

## VIP heatmap
```{r}
library(ggplot2)
library(hrbrthemes)

#heatmapData = read_csv("Data/VIP Heatmap Data.csv", show_col_types = FALSE)
#heatmapData$Vars = factor(heatmapData$Vars, levels = rev(heatmapData$Vars))


heatmapData = bind_rows(MSC_vip, TSC_vip, PSC_vip, BAB_vip) %>%
  pivot_longer(cols = everything(), names_to = "Dataset", values_to = "Vars") %>% 
  count(Vars, Dataset) 


heatmapData = heatmapData %>%
  mutate(Vars = case_when(
    Vars == "CertYear" ~ "Certification Year",
    Vars == "CowNum" ~ "Cow Number",
    Vars == "PplNumPerWk" ~ "Number of people per week",
    Vars == "SPCvar" ~ "SPC variability",
    Vars == "StockDen" ~ "Stock Density",
    Vars == "PplNumPerShift" ~ "Number of people per shift",
    Vars == "PC1" ~ "Principal component 1 associated with temperature",
    Vars == "ClipFlame_Yes" ~ "Clipping and flaming udders",
    Vars == "NonFamEmpNum" ~ "Number of non-family employee",
    Vars == "PC4" ~ "Principal component 4 associated with precipitation and wind gust",
    Vars == "CornSilage_Yes" ~ "Use of corn silage",
    Vars == "Parlor_Yes" ~ "Presence of parlor",
    Vars == "PC2" ~ "Principal component 2 associated with humidity",
    Vars == "Haylage_Yes" ~ "Use of haylage",
    Vars == "CowMilkLoc_Stall.barn" ~ "Stall barn as milking location",
    Vars == "ParlorManScrap" ~ "Manual scrapping of parlor",
    Vars == "ParlorHose" ~ "Use of hose to clean parlor",
    Vars == "GloveFreq_unknown" ~ "Unknown frequency of changing glove",
    Vars == "GloveFreq_X1" ~ "Changing glove once per day",
    Vars == "CowParlorClean_Yes" ~ "Presence of cow during parlor/milking area cleaning",
    Vars == "CornMeal_Yes" ~ "Corn meal",
    Vars == "TowelMacDry" ~ "Use of machine to dry towel",
    Vars == "StallCleanFreq_X2x.day" ~ "Cleaning stall 2 times per day",
    Vars == "PC3" ~ "Principal component 3 associated with precipitation and wind gust",
    Vars == "NonFamEmp_Yes" ~ "Presence of non-family employees to milk cows",
    Vars == "HouseStyle_Free.stalls" ~ "Free stalls",
    Vars == "CowWaitMilk_Yes" ~ "Cow waiting in the a holding area to be milked",
    Vars == "Bed_Sawdust" ~ "Use of sawdust as bedding material",
    Vars == "TowelType_Paper" ~ "Use of paper as towel",
    Vars == "Glove_Yes" ~ "Use of glove during milking",
    Vars == "CowHoldClean_No.holding.area" ~ "No holding area for cow waiting to be milked",
    Vars == "ClosedHerd_Yes" ~ "Closed herd",
    Vars == "TowelDeter" ~ "Use of detergent to clean towel",
    Vars == "PreDipType_Iodine.based" ~ "Use of iodine based pre-dip",
    Vars == "ParlorFluSys" ~ "Use of a flushing system to clean parlor",
    Vars == "PC5" ~ "Principal componenet 5 associated with precipitation and wind speed",
    Vars == "HoldManScrap" ~ "Manual scrapping the holding area",
    Vars == "DryMatPercent_X40.70." ~ "Dry matter intake percentage between 40 and 70",
    Vars == "BedAdd_no" ~ "No bedding additives",
    Vars == "BedAddFreq_X...2x.per.day" ~ "Frequency of adding bedding more than 2 times per day",
    Vars == "FullEmpNum" ~ "Number of full-time employees",
    Vars == "PartEmp_Yes" ~ "Presence of part-time employees to milk cows",
    Vars == "PastureTime" ~ "Hours cows spend on pasture",
    Vars == "DryHay_Yes" ~ "Feeding dry hay",
    Vars == "HouseStyle_Tie.stalls.or.stanchions" ~ "Tie stalls or stanchions",
    Vars == "FeedPurchase_Yes" ~ "Purchase feed",
    TRUE ~ Vars
  ))

heatmapData = heatmapData %>%
  mutate(Dataset = factor(Dataset, levels = c("All", "Parlor", "noParlor", "Pasture", "noPasture", "newFarm", "oldFarm"))) 

total_counts = heatmapData %>%
  group_by(Vars) %>%
  summarise(TotalCount = sum(n)) %>%
  arrange(TotalCount)

heatmapData = heatmapData %>%
  mutate(Vars = factor(Vars, levels = total_counts$Vars))

heatMap = heatmapData %>% 
  ggplot(aes(Dataset, Vars, fill = n)) + 
  geom_tile() +
  scale_fill_gradient(low="lightblue", high="darkblue") +
  theme_classic() +
  theme(axis.text = element_text(size = 6))
heatMap    

ggsave(heatMap, file = "Manuscript/heat map.tiff", height = 4, width = 8, units = "in", dpi = "retina")
```





